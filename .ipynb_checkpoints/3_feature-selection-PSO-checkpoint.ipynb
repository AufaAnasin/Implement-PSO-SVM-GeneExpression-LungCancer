{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| Feature Selection using Particle Selection Optimization ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# from Py_FS.wrapper.nature_inspired._utilities import Solution, Data, initialize, sort_agents, display, compute_fitness, Conv_plot\n",
    "# from Py_FS.wrapper.nature_inspired._transfer_functions import get_trans_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "X_train = pd.read_csv('dataset-after-preparation/X_train.csv')\n",
    "X_test = pd.read_csv('dataset-after-preparation/X_test.csv')\n",
    "y_train = pd.read_csv('dataset-after-preparation/y_train.csv')\n",
    "y_test = pd.read_csv('dataset-after-preparation/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Variance Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VarianceThreshold' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a2a97f81f753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Total Number of feature after variance threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'VarianceThreshold' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.03)\n",
    "selector.fit_transform(X_train)\n",
    "\n",
    "#Total Number of feature after variance threshold\n",
    "len(selector.get_feature_names_out(features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the selected features to pkl \n",
    "VT_selected_feature = selector.get_feature_names_out(features_name)\n",
    "joblib.dump(VT_selected_feature, 'VT_selected_feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[VT_selected_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[VT_selected_feature])\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train[VT_selected_feature])\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=VT_selected_feature)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution():    \n",
    "    #structure of the solution \n",
    "    def __init__(self):\n",
    "        self.num_features = None\n",
    "        self.num_agents = None\n",
    "        self.max_iter = None\n",
    "        self.obj_function = None\n",
    "        self.execution_time = None\n",
    "        self.convergence_curve = {}\n",
    "        self.best_agent = None\n",
    "        self.best_fitness = None\n",
    "        self.best_accuracy = None\n",
    "        self.final_population = None\n",
    "        self.final_fitness = None\n",
    "        self.final_accuracy = None\n",
    "\n",
    "\n",
    "class Data():\n",
    "    # structure of the training data\n",
    "    def __init__(self):\n",
    "        self.train_X = None\n",
    "        self.train_Y = None\n",
    "        self.val_X = None\n",
    "        self.val_Y = None\n",
    "        \n",
    "def compute_fitness(agent, train_X, test_X, train_Y, test_Y, weight_acc=0.9):\n",
    "    # compute a basic fitness measure\n",
    "    if(weight_acc == None):\n",
    "        weight_acc = 0.9\n",
    "\n",
    "    weight_feat = 1 - weight_acc\n",
    "    num_features = agent.shape[0]\n",
    "    \n",
    "    acc = compute_accuracy(agent, train_X, test_X, train_Y, test_Y)\n",
    "    feat = (num_features - np.sum(agent))/num_features\n",
    "\n",
    "    fitness = weight_acc * acc + weight_feat * feat\n",
    "    return fitness\n",
    "\n",
    "\n",
    "def Conv_plot(convergence_curve):\n",
    "    # plot convergence curves\n",
    "    num_iter = len(convergence_curve['fitness'])\n",
    "    iters = np.arange(num_iter) + 1\n",
    "    fig, axes = plt.subplots(1)\n",
    "    fig.tight_layout(pad = 5) \n",
    "    fig.suptitle('Convergence Curves')\n",
    "    \n",
    "    axes.set_title('Convergence of Fitness over Iterations')\n",
    "    axes.set_xlabel('Iteration')\n",
    "    axes.set_ylabel('Avg. Fitness')\n",
    "    axes.plot(iters, convergence_curve['fitness'])\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "def get_trans_function(shape):\n",
    "    if (shape.lower() == 's'):\n",
    "        return sigmoid\n",
    "\n",
    "    elif (shape.lower() == 'v'):\n",
    "        return v_func\n",
    "\n",
    "    elif(shape.lower() == 'u'):\n",
    "        return u_func\n",
    "\n",
    "    else:\n",
    "        print('\\n[Error!] We don\\'t currently support {}-shaped transfer functions...\\n'.format(shape))\n",
    "        exit(1)\n",
    "        \n",
    "\n",
    "def sigmoid(val):\n",
    "    if val < 0:\n",
    "        return 1 - 1/(1 + np.exp(val))\n",
    "    else:\n",
    "        return 1/(1 + np.exp(-val))\n",
    "\n",
    "\n",
    "def initialize(num_agents, num_features):\n",
    "    # define min and max number of features\n",
    "    min_features = int(0.3 * num_features)\n",
    "    max_features = int(0.6 * num_features)\n",
    "\n",
    "    # initialize the agents with zeros\n",
    "    agents = np.zeros((num_agents, num_features))\n",
    "\n",
    "    # select random features for each agent\n",
    "    for agent_no in range(num_agents):\n",
    "\n",
    "        # find random indices\n",
    "        cur_count = np.random.randint(min_features, max_features)\n",
    "        temp_vec = np.random.rand(1, num_features)\n",
    "        temp_idx = np.argsort(temp_vec)[0][0:cur_count]\n",
    "\n",
    "        # select the features with the ranom indices\n",
    "        agents[agent_no][temp_idx] = 1   \n",
    "\n",
    "    return agents\n",
    "\n",
    "def sort_agents(agents, obj, data, fitness=None):\n",
    "    # sort the agents according to fitness\n",
    "    train_X, val_X, train_Y, val_Y = data.train_X, data.val_X, data.train_Y, data.val_Y\n",
    "    (obj_function, weight_acc) = obj\n",
    "   \n",
    "    if fitness is None:\n",
    "        # if there is only one agent\n",
    "        if len(agents.shape) == 1:\n",
    "            num_agents = 1\n",
    "            fitness = obj_function(agents, train_X, val_X, train_Y, val_Y, weight_acc)\n",
    "            return agents, fitness\n",
    "\n",
    "        # for multiple agents\n",
    "        else:\n",
    "            num_agents = agents.shape[0]\n",
    "            fitness = np.zeros(num_agents)\n",
    "            for id, agent in enumerate(agents):\n",
    "                fitness[id] = obj_function(agent, train_X, val_X, train_Y, val_Y, weight_acc)\n",
    "\n",
    "    idx = np.argsort(-fitness)\n",
    "    sorted_agents = agents[idx].copy()\n",
    "    sorted_fitness = fitness[idx].copy()\n",
    "\n",
    "    return sorted_agents, sorted_fitness\n",
    "\n",
    "def compute_accuracy(agent, train_X, test_X, train_Y, test_Y): \n",
    "    # compute classification accuracy of the given agents\n",
    "    cols = np.flatnonzero(agent)     \n",
    "    if(cols.shape[0] == 0):\n",
    "        return 0    \n",
    "    clf = SVC(kernel='linear')\n",
    "    train_data = train_X[:,cols]\n",
    "    train_label = train_Y\n",
    "    test_data = test_X[:,cols]\n",
    "    test_label = test_Y\n",
    "\n",
    "    clf.fit(train_data,train_label)\n",
    "    acc = clf.score(test_data,test_label)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO(num_agents, max_iter, weight_acc, train_data, train_label, obj_function=compute_fitness, trans_func_shape='s', save_conv_graph=False):\n",
    "    \n",
    "    # Particle Swarm Optimizer\n",
    "    ############################### Parameters ####################################\n",
    "    #                                                                             #\n",
    "    #   num_agents: number of particles                                           #\n",
    "    #   max_iter: maximum number of generations                                   #\n",
    "    #   train_data: training samples of data                                      #\n",
    "    #   train_label: class labels for the training samples                        #                \n",
    "    #   obj_function: the function to maximize while doing feature selection      #\n",
    "    #   trans_function_shape: shape of the transfer function used                 #\n",
    "    #   save_conv_graph: boolean value for saving convergence graph               #\n",
    "    #                                                                             #\n",
    "    ###############################################################################\n",
    "    \n",
    "    short_name = 'PSO'\n",
    "    agent_name = 'Particle'\n",
    "    train_data, train_label = np.array(train_data), np.array(train_label)\n",
    "    num_features = train_data.shape[1]\n",
    "    trans_function = get_trans_function(trans_func_shape)\n",
    "    \n",
    "    # setting up the objectives\n",
    "    weight_acc = None\n",
    "    if(obj_function==compute_fitness):\n",
    "        # weight_acc = float(input('Weight for the classification accuracy [0-1]: '))\n",
    "        weight_acc = weight_acc \n",
    "    obj = (obj_function, weight_acc)\n",
    "    compute_accuracy = (compute_fitness, 1) # compute_accuracy is just compute_fitness with accuracy weight as 1\n",
    "\n",
    "    # initialize particles and Leader (the agent with the max fitness)\n",
    "    particles = initialize(num_agents, num_features)\n",
    "    fitness = np.zeros(num_agents)\n",
    "    accuracy = np.zeros(num_agents)\n",
    "    Leader_agent = np.zeros((1, num_features))\n",
    "    Leader_fitness = float(\"-inf\")\n",
    "    Leader_accuracy = float(\"-inf\")\n",
    "\n",
    "    # initialize convergence curves\n",
    "    convergence_curve = {}\n",
    "    convergence_curve['fitness'] = np.zeros(max_iter)\n",
    "\n",
    "    # initialize data class\n",
    "    \n",
    "    data = Data()\n",
    "    val_size = 0.3\n",
    "    # val_size = float(input('Enter the percentage of data wanted for valdiation [0, 100]: '))/100\n",
    "    data.train_X, data.val_X, data.train_Y, data.val_Y = train_test_split(train_data, train_label, stratify=train_label, test_size=val_size)\n",
    "    \n",
    "\n",
    "    # create a solution object\n",
    "    solution = Solution()\n",
    "    solution.num_agents = num_agents\n",
    "    solution.max_iter = max_iter\n",
    "    solution.num_features = num_features\n",
    "    solution.obj_function = obj_function\n",
    "\n",
    "    # rank initial particles\n",
    "    particles, fitness = sort_agents(particles, obj, data)\n",
    "\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # initialize global and local best particles\n",
    "    globalBestParticle = [0 for i in range(num_features)]\n",
    "    globalBestFitness = float(\"-inf\")\n",
    "    localBestParticle = [ [ 0 for i in range(num_features) ] for j in range(num_agents) ] \n",
    "    localBestFitness = [float(\"-inf\") for i in range(num_agents) ]\n",
    "    weight = 1.0 \n",
    "    velocity = [ [ 0.0 for i in range(num_features) ] for j in range(num_agents) ]\n",
    "    \n",
    "    for iter_no in range(max_iter):\n",
    "        print('\\n================================================================================')\n",
    "        print('                          Iteration - {}'.format(iter_no+1))\n",
    "        print('================================================================================\\n')\n",
    "        \n",
    "        # update weight\n",
    "        weight = 1.0 - (iter_no / max_iter)\n",
    "        \n",
    "        # update the velocity\n",
    "        for i in range(num_agents):\n",
    "            for j in range(num_features):\n",
    "                velocity[i][j] = (weight*velocity[i][j])\n",
    "                r1, r2 = np.random.random(2)\n",
    "                velocity[i][j] = velocity[i][j] + (r1 * (localBestParticle[i][j] - particles[i][j]))\n",
    "                velocity[i][j] = velocity[i][j] + (r2 * (globalBestParticle[j] - particles[i][j]))\n",
    "       \n",
    "        # updating position of particles\n",
    "        for i in range(num_agents):\n",
    "            for j in range(num_features):\n",
    "                trans_value = trans_function(velocity[i][j])\n",
    "                if (np.random.random() < trans_value): \n",
    "                    particles[i][j] = 1\n",
    "                else:\n",
    "                    particles[i][j] = 0\n",
    "                 \n",
    "        # updating fitness of particles\n",
    "        particles, fitness = sort_agents(particles, obj, data)\n",
    "        display(particles, fitness, agent_name)\n",
    "        \n",
    "        \n",
    "        # updating the global best and local best particles\n",
    "        for i in range(num_agents):\n",
    "            if fitness[i]>localBestFitness[i]:\n",
    "                localBestFitness[i]=fitness[i]\n",
    "                localBestParticle[i]=particles[i][:]\n",
    "\n",
    "            if fitness[i]>globalBestFitness:\n",
    "                globalBestFitness=fitness[i]\n",
    "                globalBestParticle=particles[i][:]\n",
    "\n",
    "        # update Leader (best agent)\n",
    "        if globalBestFitness > Leader_fitness:\n",
    "            Leader_agent = globalBestParticle.copy()\n",
    "            Leader_fitness = globalBestFitness.copy()\n",
    "\n",
    "        convergence_curve['fitness'][iter_no] = np.mean(fitness)\n",
    "\n",
    "    # compute final accuracy\n",
    "    Leader_agent, Leader_accuracy = sort_agents(Leader_agent, compute_accuracy, data)\n",
    "    particles, accuracy = sort_agents(particles, compute_accuracy, data)\n",
    "\n",
    "    print('\\n================================================================================')\n",
    "    print('                                    Final Result                                  ')\n",
    "    print('================================================================================\\n')\n",
    "    print('Leader ' + agent_name + ' Dimension : {}'.format(int(np.sum(Leader_agent))))\n",
    "    print('Leader ' + agent_name + ' Fitness : {}'.format(Leader_fitness))\n",
    "    print('Leader ' + agent_name + ' Classification Accuracy : {}'.format(Leader_accuracy))\n",
    "    print('\\n================================================================================\\n')\n",
    "\n",
    "    # stop timer\n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time\n",
    "\n",
    "    # plot convergence graph\n",
    "    fig, axes = Conv_plot(convergence_curve)\n",
    "    # if(save_conv_graph):\n",
    "    #     plt.savefig('convergence_graph_'+ short_name + '.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    # update attributes of solution\n",
    "    solution.best_agent = Leader_agent\n",
    "    solution.best_fitness = Leader_fitness\n",
    "    solution.best_accuracy = Leader_accuracy\n",
    "    solution.convergence_curve = convergence_curve\n",
    "    solution.final_particles = particles\n",
    "    solution.final_fitness = fitness\n",
    "    solution.final_accuracy = accuracy\n",
    "    solution.execution_time = exec_time\n",
    "\n",
    "    return solution\n",
    "\n",
    "\n",
    "# if __name__ == '__main__': \n",
    "    \n",
    "#     # data = datasets.load_digits()\n",
    "#     PSO(20, 100, 0.8, X_train, y_train, save_conv_graph=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 20; max_iter = 100;\n",
    "solution = PSO(num_agents, max_iter, weight_acc=0.8, train_data = X_train, train_label = y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.best_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = []\n",
    "chromosome_dimension = []\n",
    "chromosome_fitness = []\n",
    "chromosome_acc = []\n",
    "names = []\n",
    "\n",
    "for i in range(20):\n",
    "    num_agents = 20; max_iter = 100;\n",
    "    solution = PSO(num_agents, max_iter, weight_acc=0.8, train_data = X_train[VT_selected_feature], train_label = y_train.values.ravel())  \n",
    "    iteration.append(i)\n",
    "    chromosome_dimension.append(int(np.sum(solution.best_agent)))\n",
    "    chromosome_fitness.append(solution.best_fitness)\n",
    "    chromosome_acc.append(solution.best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing PSO-SVM Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15f7ea1ae933a3bca0210cb7572c0952f08b91c912628f3b83103bd71cce445f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
