{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78c298b",
   "metadata": {},
   "source": [
    "|| Feature Selection using Particle Swarm Optimizer (Zoofs) ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ad9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoofs.baseoptimizationalgorithm import BaseOptimizationAlgorithm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging as log\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import scipy\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38222f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "X_train = pd.read_csv('https://raw.githubusercontent.com/AufaAnasin/Implement-PSO-SVM-GeneExpression-LungCancer/main/dataset-after-preparation/X_train.csv')\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/AufaAnasin/Implement-PSO-SVM-GeneExpression-LungCancer/main/dataset-after-preparation/X_test.csv')\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/AufaAnasin/Implement-PSO-SVM-GeneExpression-LungCancer/main/dataset-after-preparation/y_train.csv')\n",
    "y_test = pd.read_csv('https://raw.githubusercontent.com/AufaAnasin/Implement-PSO-SVM-GeneExpression-LungCancer/main/dataset-after-preparation/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556ba195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 22214)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c094da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e87712e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into X_train and X_valid\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e8cc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65, 22214), (28, 22214))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20815295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Variance Threshold\n",
    "features_name = X_train.columns.to_list()\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.030)\n",
    "selector.fit_transform(X_train)\n",
    "\n",
    "#Total Number of feature after variance threshold\n",
    "len(selector.get_feature_names_out(features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ddc502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VT_selected_feature_Zoo.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "VT_selected_feature_Zoo = selector.get_feature_names_out(features_name)\n",
    "joblib.dump(VT_selected_feature_Zoo, 'VT_selected_feature_Zoo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "742fdcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>209720_s_at</th>\n",
       "      <th>217653_x_at</th>\n",
       "      <th>215604_x_at</th>\n",
       "      <th>214594_x_at</th>\n",
       "      <th>216609_at</th>\n",
       "      <th>205292_s_at</th>\n",
       "      <th>208864_s_at</th>\n",
       "      <th>217679_x_at</th>\n",
       "      <th>206056_x_at</th>\n",
       "      <th>217715_x_at</th>\n",
       "      <th>...</th>\n",
       "      <th>206276_at</th>\n",
       "      <th>213998_s_at</th>\n",
       "      <th>221728_x_at</th>\n",
       "      <th>214370_at</th>\n",
       "      <th>206529_x_at</th>\n",
       "      <th>212657_s_at</th>\n",
       "      <th>202499_s_at</th>\n",
       "      <th>209351_at</th>\n",
       "      <th>211719_x_at</th>\n",
       "      <th>214218_s_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.232569</td>\n",
       "      <td>2.138282</td>\n",
       "      <td>2.688031</td>\n",
       "      <td>2.651118</td>\n",
       "      <td>2.117078</td>\n",
       "      <td>3.055830</td>\n",
       "      <td>3.265455</td>\n",
       "      <td>2.699097</td>\n",
       "      <td>2.293292</td>\n",
       "      <td>2.298984</td>\n",
       "      <td>...</td>\n",
       "      <td>2.358706</td>\n",
       "      <td>2.209866</td>\n",
       "      <td>2.402188</td>\n",
       "      <td>1.885983</td>\n",
       "      <td>1.827324</td>\n",
       "      <td>2.906680</td>\n",
       "      <td>2.468566</td>\n",
       "      <td>2.814156</td>\n",
       "      <td>3.176087</td>\n",
       "      <td>1.668904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3.237282</td>\n",
       "      <td>2.052387</td>\n",
       "      <td>2.409666</td>\n",
       "      <td>2.285882</td>\n",
       "      <td>1.982433</td>\n",
       "      <td>3.169172</td>\n",
       "      <td>3.364678</td>\n",
       "      <td>2.431334</td>\n",
       "      <td>1.963884</td>\n",
       "      <td>2.008092</td>\n",
       "      <td>...</td>\n",
       "      <td>2.859518</td>\n",
       "      <td>2.238691</td>\n",
       "      <td>2.282931</td>\n",
       "      <td>1.961769</td>\n",
       "      <td>1.832160</td>\n",
       "      <td>3.004747</td>\n",
       "      <td>2.063678</td>\n",
       "      <td>2.064597</td>\n",
       "      <td>2.769440</td>\n",
       "      <td>1.632042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.095520</td>\n",
       "      <td>2.010084</td>\n",
       "      <td>2.386910</td>\n",
       "      <td>2.392668</td>\n",
       "      <td>2.242499</td>\n",
       "      <td>3.137576</td>\n",
       "      <td>3.406201</td>\n",
       "      <td>2.542693</td>\n",
       "      <td>2.098109</td>\n",
       "      <td>2.165640</td>\n",
       "      <td>...</td>\n",
       "      <td>2.549053</td>\n",
       "      <td>2.203878</td>\n",
       "      <td>3.021885</td>\n",
       "      <td>2.328782</td>\n",
       "      <td>2.649006</td>\n",
       "      <td>3.141030</td>\n",
       "      <td>2.375305</td>\n",
       "      <td>2.955892</td>\n",
       "      <td>2.579092</td>\n",
       "      <td>2.482838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.890683</td>\n",
       "      <td>2.119402</td>\n",
       "      <td>2.423655</td>\n",
       "      <td>2.201289</td>\n",
       "      <td>2.233899</td>\n",
       "      <td>3.044682</td>\n",
       "      <td>3.359560</td>\n",
       "      <td>2.443716</td>\n",
       "      <td>2.116512</td>\n",
       "      <td>2.232830</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292536</td>\n",
       "      <td>2.016123</td>\n",
       "      <td>2.298543</td>\n",
       "      <td>1.995867</td>\n",
       "      <td>1.570787</td>\n",
       "      <td>2.843499</td>\n",
       "      <td>1.944908</td>\n",
       "      <td>2.375459</td>\n",
       "      <td>2.765676</td>\n",
       "      <td>1.691548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.030821</td>\n",
       "      <td>1.957657</td>\n",
       "      <td>2.469965</td>\n",
       "      <td>2.248177</td>\n",
       "      <td>2.139794</td>\n",
       "      <td>3.058196</td>\n",
       "      <td>3.336429</td>\n",
       "      <td>2.374257</td>\n",
       "      <td>1.947060</td>\n",
       "      <td>1.983662</td>\n",
       "      <td>...</td>\n",
       "      <td>2.614953</td>\n",
       "      <td>2.113229</td>\n",
       "      <td>2.333040</td>\n",
       "      <td>2.226065</td>\n",
       "      <td>2.103168</td>\n",
       "      <td>3.206871</td>\n",
       "      <td>2.145947</td>\n",
       "      <td>2.202494</td>\n",
       "      <td>2.244570</td>\n",
       "      <td>1.711798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.299760</td>\n",
       "      <td>2.658968</td>\n",
       "      <td>2.907211</td>\n",
       "      <td>3.026774</td>\n",
       "      <td>2.132599</td>\n",
       "      <td>3.051177</td>\n",
       "      <td>3.200636</td>\n",
       "      <td>3.050772</td>\n",
       "      <td>2.445860</td>\n",
       "      <td>2.466112</td>\n",
       "      <td>...</td>\n",
       "      <td>2.399776</td>\n",
       "      <td>2.200251</td>\n",
       "      <td>2.332697</td>\n",
       "      <td>1.760016</td>\n",
       "      <td>1.740199</td>\n",
       "      <td>2.618065</td>\n",
       "      <td>1.725885</td>\n",
       "      <td>2.707471</td>\n",
       "      <td>2.518330</td>\n",
       "      <td>1.628255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.294696</td>\n",
       "      <td>2.206173</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.618382</td>\n",
       "      <td>2.071573</td>\n",
       "      <td>3.134396</td>\n",
       "      <td>3.306939</td>\n",
       "      <td>2.683545</td>\n",
       "      <td>2.192409</td>\n",
       "      <td>2.097672</td>\n",
       "      <td>...</td>\n",
       "      <td>2.928916</td>\n",
       "      <td>2.471752</td>\n",
       "      <td>2.292899</td>\n",
       "      <td>1.725882</td>\n",
       "      <td>1.578825</td>\n",
       "      <td>2.579634</td>\n",
       "      <td>1.686202</td>\n",
       "      <td>2.312515</td>\n",
       "      <td>2.451961</td>\n",
       "      <td>1.529045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3.182757</td>\n",
       "      <td>2.047357</td>\n",
       "      <td>2.534126</td>\n",
       "      <td>2.637977</td>\n",
       "      <td>2.111175</td>\n",
       "      <td>3.125710</td>\n",
       "      <td>3.431716</td>\n",
       "      <td>2.521397</td>\n",
       "      <td>1.978242</td>\n",
       "      <td>2.037692</td>\n",
       "      <td>...</td>\n",
       "      <td>2.581282</td>\n",
       "      <td>2.158209</td>\n",
       "      <td>2.292144</td>\n",
       "      <td>1.899264</td>\n",
       "      <td>1.611884</td>\n",
       "      <td>2.721762</td>\n",
       "      <td>1.741514</td>\n",
       "      <td>2.294170</td>\n",
       "      <td>2.562159</td>\n",
       "      <td>1.619081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.058981</td>\n",
       "      <td>2.088016</td>\n",
       "      <td>2.461772</td>\n",
       "      <td>2.179160</td>\n",
       "      <td>1.984155</td>\n",
       "      <td>3.076958</td>\n",
       "      <td>3.233009</td>\n",
       "      <td>2.527380</td>\n",
       "      <td>1.976614</td>\n",
       "      <td>2.074380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.434002</td>\n",
       "      <td>2.333456</td>\n",
       "      <td>2.948457</td>\n",
       "      <td>1.766857</td>\n",
       "      <td>1.714645</td>\n",
       "      <td>2.576441</td>\n",
       "      <td>1.658419</td>\n",
       "      <td>2.118980</td>\n",
       "      <td>2.868666</td>\n",
       "      <td>2.425684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2.374161</td>\n",
       "      <td>2.538664</td>\n",
       "      <td>2.852416</td>\n",
       "      <td>2.765521</td>\n",
       "      <td>1.803622</td>\n",
       "      <td>1.756685</td>\n",
       "      <td>2.380722</td>\n",
       "      <td>3.020301</td>\n",
       "      <td>2.602028</td>\n",
       "      <td>2.703493</td>\n",
       "      <td>...</td>\n",
       "      <td>2.617861</td>\n",
       "      <td>2.276191</td>\n",
       "      <td>2.473939</td>\n",
       "      <td>1.884053</td>\n",
       "      <td>2.044320</td>\n",
       "      <td>2.867227</td>\n",
       "      <td>2.085646</td>\n",
       "      <td>2.188187</td>\n",
       "      <td>2.504480</td>\n",
       "      <td>1.772305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 1028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    209720_s_at  217653_x_at  215604_x_at  214594_x_at  216609_at  \\\n",
       "31     3.232569     2.138282     2.688031     2.651118   2.117078   \n",
       "77     3.237282     2.052387     2.409666     2.285882   1.982433   \n",
       "9      3.095520     2.010084     2.386910     2.392668   2.242499   \n",
       "70     2.890683     2.119402     2.423655     2.201289   2.233899   \n",
       "5      3.030821     1.957657     2.469965     2.248177   2.139794   \n",
       "..          ...          ...          ...          ...        ...   \n",
       "20     3.299760     2.658968     2.907211     3.026774   2.132599   \n",
       "60     3.294696     2.206173     2.602277     2.618382   2.071573   \n",
       "71     3.182757     2.047357     2.534126     2.637977   2.111175   \n",
       "14     3.058981     2.088016     2.461772     2.179160   1.984155   \n",
       "51     2.374161     2.538664     2.852416     2.765521   1.803622   \n",
       "\n",
       "    205292_s_at  208864_s_at  217679_x_at  206056_x_at  217715_x_at  ...  \\\n",
       "31     3.055830     3.265455     2.699097     2.293292     2.298984  ...   \n",
       "77     3.169172     3.364678     2.431334     1.963884     2.008092  ...   \n",
       "9      3.137576     3.406201     2.542693     2.098109     2.165640  ...   \n",
       "70     3.044682     3.359560     2.443716     2.116512     2.232830  ...   \n",
       "5      3.058196     3.336429     2.374257     1.947060     1.983662  ...   \n",
       "..          ...          ...          ...          ...          ...  ...   \n",
       "20     3.051177     3.200636     3.050772     2.445860     2.466112  ...   \n",
       "60     3.134396     3.306939     2.683545     2.192409     2.097672  ...   \n",
       "71     3.125710     3.431716     2.521397     1.978242     2.037692  ...   \n",
       "14     3.076958     3.233009     2.527380     1.976614     2.074380  ...   \n",
       "51     1.756685     2.380722     3.020301     2.602028     2.703493  ...   \n",
       "\n",
       "    206276_at  213998_s_at  221728_x_at  214370_at  206529_x_at  212657_s_at  \\\n",
       "31   2.358706     2.209866     2.402188   1.885983     1.827324     2.906680   \n",
       "77   2.859518     2.238691     2.282931   1.961769     1.832160     3.004747   \n",
       "9    2.549053     2.203878     3.021885   2.328782     2.649006     3.141030   \n",
       "70   2.292536     2.016123     2.298543   1.995867     1.570787     2.843499   \n",
       "5    2.614953     2.113229     2.333040   2.226065     2.103168     3.206871   \n",
       "..        ...          ...          ...        ...          ...          ...   \n",
       "20   2.399776     2.200251     2.332697   1.760016     1.740199     2.618065   \n",
       "60   2.928916     2.471752     2.292899   1.725882     1.578825     2.579634   \n",
       "71   2.581282     2.158209     2.292144   1.899264     1.611884     2.721762   \n",
       "14   2.434002     2.333456     2.948457   1.766857     1.714645     2.576441   \n",
       "51   2.617861     2.276191     2.473939   1.884053     2.044320     2.867227   \n",
       "\n",
       "    202499_s_at  209351_at  211719_x_at  214218_s_at  \n",
       "31     2.468566   2.814156     3.176087     1.668904  \n",
       "77     2.063678   2.064597     2.769440     1.632042  \n",
       "9      2.375305   2.955892     2.579092     2.482838  \n",
       "70     1.944908   2.375459     2.765676     1.691548  \n",
       "5      2.145947   2.202494     2.244570     1.711798  \n",
       "..          ...        ...          ...          ...  \n",
       "20     1.725885   2.707471     2.518330     1.628255  \n",
       "60     1.686202   2.312515     2.451961     1.529045  \n",
       "71     1.741514   2.294170     2.562159     1.619081  \n",
       "14     1.658419   2.118980     2.868666     2.425684  \n",
       "51     2.085646   2.188187     2.504480     1.772305  \n",
       "\n",
       "[65 rows x 1028 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[VT_selected_feature_Zoo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5be39538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging as log\n",
    "import scipy\n",
    "import colorlog\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "class BaseOptimizationAlgorithm(ABC):\n",
    "\n",
    "    def __init__(self,\n",
    "                 objective_function,\n",
    "                 n_iteration: int = 1000,\n",
    "                 timeout: int = None,\n",
    "                 population_size=50,\n",
    "                 minimize=True,\n",
    "                 logger=None,\n",
    "                 **kwargs):\n",
    "        self.kwargs=kwargs\n",
    "        self.objective_function = objective_function\n",
    "        self.minimize = minimize\n",
    "        self.population_size = population_size\n",
    "        self.n_iteration = n_iteration\n",
    "        self.timeout = timeout\n",
    "        self.my_logger=logger\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def _evaluate_fitness(self, model, x_train, y_train, x_valid, y_valid,particle_swarm_flag=0,dragon_fly_flag=0):\n",
    "        scores = []\n",
    "        for i, individual in enumerate(self.individuals):\n",
    "            chosen_features = [index for index in range(\n",
    "                x_train.shape[1]) if individual[index] == 1]\n",
    "            x_train_copy = x_train.iloc[:, chosen_features]\n",
    "            x_valid_copy = x_valid.iloc[:, chosen_features]\n",
    "\n",
    "            feature_hash = '_*_'.join(\n",
    "                sorted(self.feature_list[chosen_features]))\n",
    "            if feature_hash in self.feature_score_hash.keys():\n",
    "                score = self.feature_score_hash[feature_hash]\n",
    "            else:\n",
    "                score = self.objective_function(\n",
    "                    model, x_train_copy, y_train, x_valid_copy, y_valid, **self.kwargs)\n",
    "                if not(self.minimize):\n",
    "                    score = -score\n",
    "                self.feature_score_hash[feature_hash] = score\n",
    "\n",
    "            if score < self.best_score:\n",
    "                self.best_score = score\n",
    "                self.best_dim = individual\n",
    "                self.best_score_dimension = individual\n",
    "            if particle_swarm_flag:\n",
    "                if score < self.current_best_scores[i]:\n",
    "                    self.current_best_scores[i] = score\n",
    "                    self.current_best_individual_score_dimensions[i] = individual\n",
    "            if dragon_fly_flag:\n",
    "                if score > self.worst_score:\n",
    "                    self.worst_score = score\n",
    "                    self.worst_dim = individual\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "    def iteration_objective_score_monitor(self, i):\n",
    "        if self.minimize:\n",
    "            self.best_results_per_iteration[i] = {'best_score': self.best_score,\n",
    "                                                  'objective_score': np.array(self.fitness_scores).min(),\n",
    "                                                  'selected_features': list(self.feature_list[\n",
    "                                                      np.where(self.individuals[np.array(self.fitness_scores).argmin()])[0]])}\n",
    "        else:\n",
    "            self.best_results_per_iteration[i] = {'best_score': -self.best_score,\n",
    "                                                  'objective_score': -np.array(self.fitness_scores).min(),\n",
    "                                                  'selected_features': list(self.feature_list[\n",
    "                                                      np.where(self.individuals[np.array(self.fitness_scores).argmin()])[0]])}\n",
    "\n",
    "    def initialize_population(self, x):\n",
    "        self.individuals = np.random.randint(\n",
    "            0, 2, size=(self.population_size, x.shape[1]))\n",
    "\n",
    "    def _check_params(self, model, x_train, y_train, x_valid, y_valid):\n",
    "        if (self.n_iteration <= 0):\n",
    "            raise ValueError(\n",
    "                f\"n_init should be > 0, got {self.n_iteration} instead.\")\n",
    "\n",
    "        if (self.population_size <= 0):\n",
    "            raise ValueError(\n",
    "                f\"population_size should be > 0, got {self.population_size} instead.\")\n",
    "\n",
    "        if (not (callable(self.objective_function))):\n",
    "            raise TypeError(f\"objective_function should be a callable function that returns\\\n",
    "                            metric value, got {type(self.objective_function)} instead\")\n",
    "\n",
    "        if y_train is None:\n",
    "            raise ValueError(\n",
    "                f\"requires y_train to be passed, but the target y is None.\")\n",
    "\n",
    "        if x_train is None:\n",
    "            raise ValueError(\n",
    "                f\"requires X_train to be passed, but the target X_train is None.\")\n",
    "\n",
    "        if (type(x_train) != pd.core.frame.DataFrame):\n",
    "            raise TypeError(f\" X_train should be of type pandas.core.frame.DataFrame,\\\n",
    "                            got {type(x_train)} instead.\")\n",
    "\n",
    "        if (type(x_valid) != pd.core.frame.DataFrame):\n",
    "            raise TypeError(f\" X_valid should be of type pandas.core.frame.DataFrame,\\\n",
    "                            got {type(x_valid)} instead.\")\n",
    "\n",
    "        if x_train.shape[1] != x_valid.shape[1]:\n",
    "            raise ValueError(f\" X_train and X_valid should have same number of features,\\\n",
    "                             got { x_train.shape[1]},{x_valid.shape[1]} instead.\")\n",
    "\n",
    "        if x_valid is None:\n",
    "            raise ValueError(\n",
    "                f\"requires X_valid to be passed, but the target X_train is None.\")\n",
    "\n",
    "        if y_valid is None:\n",
    "            raise ValueError(\n",
    "                f\"requires X_valid to be passed, but the target y_valid is None.\")\n",
    "\n",
    "        return_val = self.objective_function(\n",
    "            model, x_train, y_train, x_valid, y_valid, **self.kwargs)\n",
    "        if (not (isinstance(return_val, (int, float)))):\n",
    "            raise TypeError(\n",
    "                f\"objective_function should return int/float value , got {type(return_val)} instead.\")\n",
    "\n",
    "    def plot_history(self):\n",
    "        \"\"\"\n",
    "        Plot objective score history\n",
    "        \"\"\"\n",
    "        res = pd.DataFrame.from_dict(self.best_results_per_iteration).T\n",
    "        res.reset_index(inplace=True)\n",
    "        res.columns = ['iteration', 'best_score',\n",
    "                       'objective_score', 'selected_features']\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=res['iteration'], y=res['objective_score'],\n",
    "                                 mode='markers', name='objective_score'))\n",
    "        fig.add_trace(go.Scatter(x=res['iteration'], y=res['best_score'],\n",
    "                                 mode='lines+markers',\n",
    "                                 name='best_score'))\n",
    "        fig.update_xaxes(title_text='Iteration')\n",
    "        fig.update_yaxes(title_text='objective_score')\n",
    "        fig.update_layout(\n",
    "            title=\"Optimization History Plot\")\n",
    "        fig.show()\n",
    "\n",
    "    def _check_individuals(self):\n",
    "        if (self.individuals.sum(axis=1) == 0).sum() > 0:\n",
    "            log.warning(str((self.individuals.sum(axis=1) ==\n",
    "                        0).sum())+' individuals went zero')\n",
    "            self.individuals[self.individuals.sum(axis=1) == 0] = np.random.randint(0, 2,\n",
    "                                                                                    (self.individuals[self.individuals.sum(axis=1) == 0].shape[0],\n",
    "                                                                                     self.individuals[self.individuals.sum(axis=1) == 0].shape[1]))\n",
    "\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        logger = logging.getLogger()\n",
    "\n",
    "        if (logger.hasHandlers()):\n",
    "            logger.handlers.clear()\n",
    "\n",
    "        # Logging info level to stdout with colors\n",
    "        terminal_handler = colorlog.StreamHandler()\n",
    "        color_formatter = colorlog.ColoredFormatter(\n",
    "            \"%(green)s [ %(asctime)s ] %(reset)s%(message)s\",\n",
    "            datefmt=None,\n",
    "            reset=True,\n",
    "            log_colors={\n",
    "                'DEBUG':    'cyan',\n",
    "                'INFO':     'green',\n",
    "                'WARNING':  'yellow',\n",
    "                'ERROR':    'red',\n",
    "                'CRITICAL': 'red,bg_white',\n",
    "            },\n",
    "            secondary_log_colors={},\n",
    "            style='%'\n",
    "        )\n",
    "        terminal_handler.setLevel(logging.DEBUG)\n",
    "        terminal_handler.setFormatter(color_formatter)\n",
    "\n",
    "        # Add handlers to logger\n",
    "        logger.addHandler(terminal_handler)\n",
    "\n",
    "        return logger\n",
    "\n",
    "    \n",
    "    def verbose_results(self,verbose, i):\n",
    "        if verbose:\n",
    "            if i==0:\n",
    "                if self.my_logger==None:\n",
    "                    self.my_logger = self._setup_logger()\n",
    "\n",
    "            fitness_scores = np.array(self.fitness_scores).min() if self.minimize else -np.array(self.fitness_scores).min()\n",
    "            best_score = self.best_score if self.minimize else -self.best_score\n",
    "\n",
    "            self.my_logger.warning(f\"Finished iteration #{i} with objective value {fitness_scores}. Current best value is {best_score} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d59f944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging as log\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import scipy\n",
    "import warnings\n",
    "\n",
    "\n",
    "class ParticleSwarmOptimization(BaseOptimizationAlgorithm):\n",
    "    def __init__(self,\n",
    "                 objective_function,\n",
    "                 n_iteration: int = 20,\n",
    "                 timeout: int = None,\n",
    "                 population_size=50,\n",
    "                 minimize=True,\n",
    "                 c1=2,\n",
    "                 c2=2,\n",
    "                 w=0.9,\n",
    "                 logger=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"       \n",
    "        Parameters\n",
    "        ----------\n",
    "        objective_function: user made function of the signature 'func(model,X_train,y_train,X_test,y_test)'\n",
    "            User defined function that returns the objective value \n",
    "        population_size: int, default=50\n",
    "            Total size of the population , default=50\n",
    "        n_iteration: int, default=20\n",
    "            Number of time the Particle Swarm Optimization algorithm will run\n",
    "        timeout: int = None\n",
    "            Stop operation after the given number of second(s).\n",
    "            If this argument is set to None, the operation is executed without time limitation and n_iteration is followed\n",
    "        minimize : bool, default=True\n",
    "            Defines if the objective value is to be maximized or minimized\n",
    "        c1: float, default=2.0\n",
    "            First acceleration constant used in particle swarm optimization\n",
    "        c2: float, default=2.0\n",
    "            Second acceleration constant used in particle swarm optimization\n",
    "        w: float, default=0.9\n",
    "            Velocity weight factor\n",
    "        logger: Logger or None, optional (default=None)\n",
    "            - accepts `logging.Logger` instance.\n",
    "        **kwargs\n",
    "            Any extra keyword argument for objective_function\n",
    "        Attributes\n",
    "        ----------\n",
    "        best_feature_list : ndarray of shape (n_features)\n",
    "            list of features with the best result of the entire run\n",
    "        \"\"\"\n",
    "        super().__init__(objective_function, n_iteration, timeout, population_size, minimize, logger, **kwargs)\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.w = w\n",
    "\n",
    "    def _evaluate_fitness(self, model, x_train, y_train, x_valid, y_valid, particle_swarm_flag=0, dragon_fly_flag=0):\n",
    "        return super()._evaluate_fitness(model, x_train, y_train, x_valid, y_valid, particle_swarm_flag, dragon_fly_flag)\n",
    "\n",
    "    def fit(self, model, X_train, y_train, X_valid, y_valid, verbose=True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------   \n",
    "        model: machine learning model's object\n",
    "            The object to be used for fitting on train data\n",
    "        X_train: pandas.core.frame.DataFrame of shape (n_samples, n_features)\n",
    "            Training input samples to be used for machine learning model\n",
    "        y_train: pandas.core.frame.DataFrame or pandas.core.series.Series of shape (n_samples)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        X_valid: pandas.core.frame.DataFrame of shape (n_samples, n_features)\n",
    "            Validation input samples\n",
    "        y_valid: pandas.core.frame.DataFrame or pandas.core.series.Series of shape (n_samples)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        verbose : bool,default=True\n",
    "            Print results for iterations\n",
    "        \"\"\"\n",
    "        self._check_params(model, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "        self.feature_score_hash = {}\n",
    "        self.feature_list = np.array(list(X_train.columns))\n",
    "        self.best_results_per_iteration = {}\n",
    "        self.best_score = np.inf\n",
    "        self.best_dim = np.ones(X_train.shape[1])\n",
    "\n",
    "        self.initialize_population(X_train)\n",
    "\n",
    "        self.current_best_individual_score_dimensions = self.individuals\n",
    "        self.current_best_scores = [np.inf]*self.population_size\n",
    "        self.gbest_individual = self.best_dim\n",
    "        self.v = np.zeros((self.population_size, X_train.shape[1]))\n",
    "\n",
    "        if (self.timeout is not None):\n",
    "            timeout_upper_limit = time.time() + self.timeout\n",
    "        else:\n",
    "            timeout_upper_limit = time.time()\n",
    "        for i in range(self.n_iteration):\n",
    "\n",
    "            if (self.timeout is not None) & (time.time() > timeout_upper_limit):\n",
    "                warnings.warn(\"Timeout occured\")\n",
    "                break\n",
    "\n",
    "            # Logging warning if any entity in the population ends up having zero selected features\n",
    "            self._check_individuals()\n",
    "\n",
    "            self.fitness_scores = self._evaluate_fitness(\n",
    "                model, X_train, y_train, X_valid, y_valid, 1, 0)\n",
    "\n",
    "            self.gbest_individual = self.best_dim\n",
    "\n",
    "            self.iteration_objective_score_monitor(i)\n",
    "\n",
    "            r1 = np.random.random((self.population_size, X_train.shape[1]))\n",
    "            r2 = np.random.random((self.population_size, X_train.shape[1]))\n",
    "\n",
    "            self.v = self.w*self.v+self.c1*r1*(self.gbest_individual-self.individuals) +\\\n",
    "                self.c2*r2 * \\\n",
    "                (self.current_best_individual_score_dimensions-self.individuals)\n",
    "            self.v = np.where(self.v > 6, 6, self.v)\n",
    "            self.v = np.where(self.v < -6, -6, self.v)\n",
    "            self.s_v = self.sigmoid(self.v)\n",
    "            self.individuals = np.where(np.random.uniform(\n",
    "                size=(self.population_size, X_train.shape[1])) < self.s_v, 1, 0)\n",
    "\n",
    "            self.verbose_results(verbose, i)\n",
    "\n",
    "            self.best_feature_list = list(\n",
    "                self.feature_list[np.where(self.best_dim)[0]])\n",
    "        return self.best_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c88c3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a5863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_valid[VT_selected_feature_Zoo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f059d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your own objective function, make sure the function receives four parameters,\n",
    "#  fit your model and return the objective value ! \n",
    "def objective_function_topass(model, X_train, y_train, X_valid, y_valid):      \n",
    "    # Using CV to calculate scores\n",
    "    score = cross_val_score(model, X_train, y_train, scoring='r2', cv=5, n_jobs=-1)\n",
    "    score = score.mean()\n",
    "    return score\n",
    "\n",
    "def features_select_PSO(model, X_train, y_train, X_valid, y_valid):\n",
    "    # create object of algorithm\n",
    "    algo_object=ParticleSwarmOptimization(objective_function_topass,n_iteration=50,\n",
    "                                population_size=20,selective_pressure=2,elitism=2,\n",
    "                                mutation_rate=0.05,minimize=False)\n",
    "\n",
    "\n",
    "    # fit the algorithm\n",
    "    algo_object.fit(model, X_train, y_train.values.ravel(), X_valid, y_valid.values.ravel(), verbose=True)\n",
    "\n",
    "    #plot your results\n",
    "    # algo_object.plot_history()\n",
    "\n",
    "    # extract the best  feature set\n",
    "    # algo_object.best_feature_list \n",
    "    return algo_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9c3d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_run_fs(n_runs, model, X_train, y_train, X_valid, y_valid):\n",
    "    all_solutions = {}\n",
    "    best_solution = {}\n",
    "    best_score  = 0\n",
    "    \n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        print(\"\\n\\n ----------------------------------------------------------------------------------------\")\n",
    "        print(f\"Run Number - {i+1}\")\n",
    "        current_solution = {}\n",
    "        \n",
    "        solution_obj = features_select_PSO(model, X_train, y_train, X_valid, y_valid)\n",
    "        last_key = max(solution_obj.best_results_per_iteration.keys())\n",
    "        \n",
    "        # solution per run time\n",
    "        solution_score = solution_obj.best_scores[last_key]\n",
    "        len_solution = len(solution_obj.best_results_per_iteration[last_key]['selected_features'])\n",
    "        list_selected_features = solution_obj.best_results_per_iteration[last_key]['selected_features']\n",
    "        plot = solution_obj.plot_history()\n",
    "        \n",
    "        current_solution['score'] = solution_score\n",
    "        current_solution['num_features'] = len_solution\n",
    "        current_solution['selected_features'] = list_selected_features\n",
    "        current_solution['plot'] = plot\n",
    "        \n",
    "        # Finding best score over runtimes\n",
    "        if (solution_score > best_score):\n",
    "            best_score = solution_score #update best score over runtimes \n",
    "            best_solution['run_id'] = i+1\n",
    "            best_solution['best_score'] = solution_score\n",
    "            best_solution['num_features'] = len_solution\n",
    "            best_solution['selected_features'] = list_selected_features\n",
    "            best_solution['plot'] = plot\n",
    "            \n",
    "        # save all solution with run id as the key\n",
    "        all_solutions[i+1] = current_solution\n",
    "    # END of LOOP\n",
    "    # append best_solution into all_solution dict\n",
    "    all_solutions['best_solution'] = best_solution\n",
    "    \n",
    "    # return dictionaries of all salution\n",
    "    return all_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a9045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_run_fs_dataframe(n_runs, model, X_train, y_train, X_valid, y_valid):\n",
    "\n",
    "    run_id = []\n",
    "    num_features = []\n",
    "    objective_scores = []\n",
    "    best_scores = []\n",
    "    selected_features = []\n",
    "    plots = []\n",
    "    \n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        print(\"\\n\\n ----------------------------------------------------------------------------------------\")\n",
    "        print(f\"Run Id - {i+1}\")\n",
    "        best_objective_score = 0\n",
    "        \n",
    "        solution_obj = features_select_PSO(model, X_train, y_train, X_valid, y_valid)\n",
    "        \n",
    "        # Best key per GA iteration\n",
    "        # last_key = max(solution_obj.best_results_per_iteration.keys())\n",
    "        for j in range(len(solution_obj.best_results_per_iteration)):\n",
    "            if solution_obj.best_results_per_iteration[j]['objective_score'] > best_objective_score:\n",
    "                best_objective_score = solution_obj.best_results_per_iteration[j]['objective_score']\n",
    "                best_key = j\n",
    "        \n",
    "        # solution per run time\n",
    "        solution_objective_score = solution_obj.best_results_per_iteration[best_key]['objective_score']\n",
    "        solution_best_score = solution_obj.best_results_per_iteration[best_key]['best_score']\n",
    "        len_solution = len(solution_obj.best_results_per_iteration[best_key]['selected_features'])\n",
    "        list_selected_features = solution_obj.best_results_per_iteration[best_key]['selected_features']\n",
    "        plot = solution_obj.plot_history()\n",
    "        \n",
    "        # append solution into a list\n",
    "        run_id.append(i+1)\n",
    "        num_features.append(len_solution)\n",
    "        objective_scores.append(solution_objective_score)\n",
    "        best_scores.append(solution_best_score)\n",
    "        selected_features.append(list_selected_features)\n",
    "        plots.append(plot)\n",
    "        \n",
    "    # END of LOOP\n",
    "    \n",
    "    # Create dataframe of the solutions\n",
    "    dict_solution = {'run_id': run_id, 'num_features': num_features, 'objective_scores' : objective_scores,\n",
    "                    'best_scores' : best_scores, 'selected_features' : selected_features, 'plot' : plots}\n",
    "    df_solution = pd.DataFrame(data=dict_solution)\n",
    "    \n",
    "    # return dictionaries of all salution\n",
    "    return df_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe06586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------\n",
      "Run Id - 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "objective_function_topass() got an unexpected keyword argument 'selective_pressure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5753c2b45233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msvr_linear_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Multiple run GA with those machine learning model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msolutions_linear_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiple_run_fs_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvr_linear_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msolutions_linear_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-e681dcfe4f27>\u001b[0m in \u001b[0;36mmultiple_run_fs_dataframe\u001b[1;34m(n_runs, model, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mbest_objective_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0msolution_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_select_PSO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Best key per GA iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-f193f7ec5228>\u001b[0m in \u001b[0;36mfeatures_select_PSO\u001b[1;34m(model, X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# fit the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0malgo_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#plot your results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-8efe960be386>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, X_train, y_train, X_valid, y_valid, verbose)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mPrint\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \"\"\"\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_score_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-f3d98058cfe4>\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self, model, x_train, y_train, x_valid, y_valid)\u001b[0m\n\u001b[0;32m    126\u001b[0m                 f\"requires X_valid to be passed, but the target y_valid is None.\")\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         return_val = self.objective_function(\n\u001b[0m\u001b[0;32m    129\u001b[0m             model, x_train, y_train, x_valid, y_valid, **self.kwargs)\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: objective_function_topass() got an unexpected keyword argument 'selective_pressure'"
     ]
    }
   ],
   "source": [
    "### TEST NEW FUNCTION\n",
    "\n",
    "# Define machine learning model\n",
    "svr_linear_model = SVR(kernel='linear')\n",
    "# Multiple run GA with those machine learning model\n",
    "solutions_linear_df = multiple_run_fs_dataframe(20, svr_linear_model, X_train, y_train, X_valid, y_valid)\n",
    "solutions_linear_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
